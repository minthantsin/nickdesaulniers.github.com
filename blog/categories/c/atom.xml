<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: C | Nick Desaulniers]]></title>
  <link href="http://nickdesaulniers.github.io/blog/categories/c/atom.xml" rel="self"/>
  <link href="http://nickdesaulniers.github.io/"/>
  <updated>2016-08-14T16:36:14-07:00</updated>
  <id>http://nickdesaulniers.github.io/</id>
  <author>
    <name><![CDATA[Nick Desaulniers]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Object Files and Symbols]]></title>
    <link href="http://nickdesaulniers.github.io/blog/2016/08/13/object-files-and-symbols/"/>
    <updated>2016-08-13T20:46:00-07:00</updated>
    <id>http://nickdesaulniers.github.io/blog/2016/08/13/object-files-and-symbols</id>
    <content type="html"><![CDATA[<p>What was supposed to be one blog post about memory segmentation turned into
what will be a series of posts.  As the first in the series, we cover the
extreme basics of object files and symbols.  In follow up posts, I
plan to talk about static libraries, dynamic libraries, dynamic linkage, memory
segments, and finally memory usage accounting.  I also cover command line tools
for working with these notions, both in Linux and OSX.</p>

<p>A quick review of the compilation+execution pipeline (for terminology):</p>

<ol>
<li>Lexing produces tokens</li>
<li>Parsing produces and abstract syntax tree</li>
<li>Analysis produces a code flow graph</li>
<li>Optimization produces a reduced code flow graph</li>
<li>Code gen produces object code</li>
<li>Linkage produces a complete executable</li>
<li>Loader instructs the OS how to start running the executable</li>
</ol>


<p>This series will focus on part #6.</p>

<p>Let&rsquo;s say you have some amazing C/C++ code,  but for separations of concerns,
you want to start moving it out into separate source files.  Whereas previously
in one file you had:</p>

<p>```c
// main.c</p>

<h1>include &lt;stdio.h></h1>

<p>void helper () {
  puts(&ldquo;helper&rdquo;);
}
int main () {
  helper();
}
```</p>

<p>You now have two source files and maybe a header:</p>

<p>```c
// main.c</p>

<h1>include &ldquo;helper.h&rdquo;</h1>

<p>int main () {
  helper();
}</p>

<p>// helper.h
void helper();</p>

<p>//helper.c</p>

<h1>include &lt;stdio.h></h1>

<h1>include &ldquo;helper.h&rdquo;</h1>

<p>void helper () {
  puts(&ldquo;helper&rdquo;);
}
```</p>

<p>In the single source version, we would have compiled and linked that with
<code>clang main.c</code> and had an executable file.  In the multiple source version, we
first compile our source files to object files, then link them altogether.
That can be done separately:</p>

<p><code>sh
$ clang -c helper.c     # produces helper.o
$ clang -c main.o       # produces main.o
$ clang main.o helper.o # produces a.out
</code></p>

<p>We can also do the compilation and linkage in one step:</p>

<p><code>sh
$ clang helper.c main.c # produces a.out
</code></p>

<p>Nothing special thus far; C/C++ 101.  In the first case of separate compilation
and linkage steps, we were left with intermediate object files (.o).  What
exactly are these?</p>

<p><a href="https://en.wikipedia.org/wiki/Object_file">Object files</a>
are almost full executables.  They contain machine code, but that code still
requires a relocation step.  It also contains metadata about the addresses of
its variables and functions (called symbols) in an associative data structure
called a
<a href="https://en.wikipedia.org/wiki/Symbol_table">symbol table</a>.
The addresses may not be the final address of the symbol in the final
executable. They also contain some information for the loader and probably some
other stuff.</p>

<p>Remember that if we fail to specify the helper object file, we&rsquo;ll get an
undefined symbol error.</p>

<p>```sh
$ clang main.c
Undefined symbols for architecture x86_64:
  &ldquo;_helper&rdquo;, referenced from:</p>

<pre><code>  _main in main-459dde.o
</code></pre>

<p>ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
```</p>

<p>The problem is main.o refers to some symbol called <code>helper</code>, but on it&rsquo;s own
doesn&rsquo;t contain any more information about it.  Let&rsquo;s say we want to know what
symbols an object file contains, or expects to find elsewhere.  Let&rsquo;s introduce
our first tool, <code>nm</code>.  <code>nm</code> will print the name list or symbol table for a
given object or executable file.  On OSX, these are prefixed with an
underscore.</p>

<p>```sh
$ nm helper.o
0000000000000000 T _helper</p>

<pre><code>             U _puts
</code></pre>

<p>$ nm main.o</p>

<pre><code>             U _helper
</code></pre>

<p>0000000000000000 T _main</p>

<p>$ nm a.out
&hellip;
0000000100000f50 T <em>helper
0000000100000f70 T </em>main</p>

<pre><code>             U _puts
</code></pre>

<p>&hellip;
```</p>

<p>Let&rsquo;s dissect what&rsquo;s going on here.  The output (as understood by <code>man 1 nm</code>)
is a space separated list of address, type, and symbol name.  We can see that
the addresses are placeholders in object files, and final in executables.  The
name should make sense; it&rsquo;s the name of the function or variable.  While I&rsquo;d
love to get in depth on the various symbol types and talk about sections, I
don&rsquo;t think I could do as great a job as Peter Van Der Linden in his book
&ldquo;Expert C Programming: Deep C Secrets.&rdquo;</p>

<p>For our case, we just care about whether the symbol in a given object file is
defined or not.  The type U (undefined) means that this symbol is referenced or
used in in this object code/executable, but it&rsquo;s value wasn&rsquo;t defined here.
When we compiled main.c alone and got the undefined symbol error, it should now
make sense why we got the undefined symbol error for helper.  main.o contains
a symbol for main, and references helper.  helper.o contains a symbol for
helper, and references to puts.  The final executable contains symbols for main
and helper and references to puts.</p>

<p>You might be wondering where puts comes from then, and why didn&rsquo;t we get an
undefined symbol error for puts like we did earlier for helper.  The answer is
the C runtime.  libc is implicitly dynamically linked to all executables
created by the C compiler.  We&rsquo;ll cover dynamic linkage in a later post in
this series.</p>

<p>When the linker performs relocation on the object files, combining them into a
final executable, it goes though placeholders of addresses and fills them in.
We did this manually in our post on
<a href="/blog/2015/05/25/interpreter-compiler-jit/">JIT compilers</a>.</p>

<p>While <code>nm</code> gave us a look into our symbol table, two other tools I use
frequently are <code>objdump</code> on Linux and <code>otool</code> on OSX.  Both of these provide
disassembled assembly instructions and their addresses.  Note how the symbols
for functions get translated into labels of the disassembled functions, and
that their address points to the first instruction in that label.  Since I&rsquo;ve
shown <code>objdump</code>
<a href="/blog/2013/04/03/basic-jit/">numerous times</a>
in
<a href="/blog/2014/04/18/lets-write-some-x86-64/">previous posts</a>,
here&rsquo;s <code>otool</code>.</p>

<p><code>sh
$ otool -tV helper.o
helper.o:
(__TEXT,__text) section
_helper:
0000000000000000    pushq    %rbp
0000000000000001    movq    %rsp, %rbp
0000000000000004    subq    $0x10, %rsp
0000000000000008    leaq    0xe(%rip), %rdi         ## literal pool for: "helper"
000000000000000f    callq    _puts
0000000000000014    movl    %eax, -0x4(%rbp)
0000000000000017    addq    $0x10, %rsp
000000000000001b    popq    %rbp
000000000000001c    retq
$ otool -tV main.o
main.o:
(__TEXT,__text) section
_main:
0000000000000000    pushq    %rbp
0000000000000001    movq    %rsp, %rbp
0000000000000004    movb    $0x0, %al
0000000000000006    callq    _helper
000000000000000b    xorl    %eax, %eax
000000000000000d    popq    %rbp
000000000000000e    retq
$ otool -tV a.out
a.out:
(__TEXT,__text) section
_helper:
0000000100000f50    pushq    %rbp
0000000100000f51    movq    %rsp, %rbp
0000000100000f54    subq    $0x10, %rsp
0000000100000f58    leaq    0x43(%rip), %rdi        ## literal pool for: "helper"
0000000100000f5f    callq    0x100000f80             ## symbol stub for: _puts
0000000100000f64    movl    %eax, -0x4(%rbp)
0000000100000f67    addq    $0x10, %rsp
0000000100000f6b    popq    %rbp
0000000100000f6c    retq
0000000100000f6d    nop
0000000100000f6e    nop
0000000100000f6f    nop
_main:
0000000100000f70    pushq    %rbp
0000000100000f71    movq    %rsp, %rbp
0000000100000f74    movb    $0x0, %al
0000000100000f76    callq    _helper
0000000100000f7b    xorl    %eax, %eax
0000000100000f7d    popq    %rbp
0000000100000f7e    retq
</code></p>

<p>Also note that for static linkage, symbols need to be unique*, as they refer to
memory locations to either read/write to in the case of variables or locations
to jump to in the case of functions.</p>

<p>```sh
$ cat double_define.c
void a () {}
void a () {}
int main () {}
$ clang double_define.c
double_define.c:2:6: error: redefinition of &lsquo;a&rsquo;
void a () {}</p>

<pre><code> ^
</code></pre>

<p>double_define.c:1:6: note: previous definition is here
void a () {}</p>

<pre><code> ^
</code></pre>

<p>1 error generated.
```</p>

<p>*: there&rsquo;s a notion of weak symbols, and some special things for dynamic
libraries we&rsquo;ll see in a follow up post.</p>

<p>Languages like C++ that support function overloading (functions with the same
name but different arguments, return types, namespaces, or class) must mangle
their function names to make them unique.</p>

<p>Code like:
```c++
namespace util {
  class Widget {</p>

<pre><code>public:
  void doSomething (bool save);
  void doSomething (int n);
</code></pre>

<p>  };
}
<code>
Will produce symbols like:
</code>sh
$ clang class.cpp -std=c++11
$ nm a.out
0000000100000f70 T <strong>ZN4util6Widget11doSomethingEb
0000000100000f60 T </strong>ZN4util6Widget11doSomethingEi
&hellip;
<code>
Note: GNU `nm` on Linux distros will have a `--demangle` option:
</code>sh
$ nm &mdash;demangle a.out
&hellip;
00000000004006d0 T util::Widget::doSomething(bool)
00000000004006a0 T util::Widget::doSomething(int)
&hellip;
<code>
On OSX, we can pipe `nm` into `c++filt`:
</code>sh
$ nm a.out | c++filt
0000000100000f70 T util::Widget::doSomething(bool)
0000000100000f60 T util::Widget::doSomething(int)
&hellip;
<code>``
Finally, if you don't have an object file, but instead a backtrace that needs
demangling, you can either invoke</code>c++filt` manually or use
<a href="http://demangler.com/">demangler.com</a>.</p>

<p>Rust also mangles its function names.  For FFI or interface with C functions,
other languages usually have to look for or expose symbols in a manner suited
to C, the lowest common denominator.
<a href="http://en.cppreference.com/w/cpp/language/language_linkage">C++</a>
has <code>extern "C"</code> blocks and
<a href="https://doc.rust-lang.org/book/ffi.html">Rust</a>
has <code>extern</code> blocks.</p>

<p>We can use <code>strip</code> to remove symbols from a binary.  This can slim down a
binary at the cost of making stack traces unreadable.  If you&rsquo;re following
along at home, try comparing the output from your disassembler and <code>nm</code> before
and after running <code>strip</code> on the executable.  Luckily, you can&rsquo;t strip the
symbols out of object files, otherwise they&rsquo;d be useless as you&rsquo;d no longer be
able to link them.</p>

<p>If we compile with the <code>-g</code> flag, we can create a different kind of symbol;
<a href="https://en.wikipedia.org/wiki/Debug_symbol">debug symbols</a>.
Depending on your compiler+host OS, you&rsquo;ll get another file you can run though
<code>nm</code> to see an entry per symbol.  You&rsquo;ll get more info by using <code>dwarfdump</code> on
this file.  Debug symbols will retain source information such as filename and
line number for all symbols.</p>

<p>This post should have been a simple refresher of some of the basics of working
with C code code. Finding symbols to be placed into a final executable and
relocating addresses are the main job of the linker, and will be the main theme
of the posts in this series. Keep your eyes out for more in this series on
memory segmentation.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Cross Compiling C/C++ for Android]]></title>
    <link href="http://nickdesaulniers.github.io/blog/2016/07/01/android-cli/"/>
    <updated>2016-07-01T22:42:00-07:00</updated>
    <id>http://nickdesaulniers.github.io/blog/2016/07/01/android-cli</id>
    <content type="html"><![CDATA[<p>Let’s say you want to build a hello world command line application in C or C++
and run it on your Android phone.  How would you go about it?  It’s not super
practical; apps visible and distributable to end users must use the framework
(AFAIK), but for folks looking to get into developing on ARM it’s they likely
have an ARM device in their pocket.</p>

<p>This post is for folks who typically invoke their compiler from the command
line, either explicitly, from build scripts, or other forms of automation.</p>

<p>At
<a href="https://twitter.com/LostOracle/status/697859368226697218">work</a>,
when working on Android, we typically checkout the entire Android source code
(<a href="https://twitter.com/LostOracle/status/702569487531249664">which is huge</a>),
use <code>lunch</code> to configure a ton of environmental variables, then use Makefiles
with lots of includes and special vars.  We don’t want to spend the time and
disk space checking out the Android source code just to have a working cross
compiler.  Luckily, the Android tools team has an excellent utility to grab a
prebuilt cross compiler.</p>

<p>This assumes you’re building from a Linux host.  Android is a distribution of
Linux, which is much easier to target from a Linux host.  At home, I’ll usually
develop on my OSX machine, ssh’d into my headless Linux box. (iTerm2 and tmux
both have exclusive features, but I currently prefer iTerm2.)</p>

<p>The first thing we want to do is fetch the
<a href="https://developer.android.com/ndk/downloads/index.html">Android NDK</a>.
Not the SDK, the NDK.</p>

<p><code>sh
➜  ~ curl -O \
  http://dl.google.com/android/repository/android-ndk-r12b-linux-x86_64.zip
➜  ~ unzip android-ndk-r12b-linux-x86_64.zip
</code></p>

<p>It would be helpful to install adb and fastboot, too.  This might be different
for your distro’s package manager.  Better yet may be to just build from
source.</p>

<p><code>sh
➜  ~ sudo apt-get install android-tools-adb android-tools-fastboot
</code></p>

<p>Now for you Android device that you want to target, you’ll want to know the
ISA.  Let’s say I want to target my Nexus 6P, which has an ARMv8-A ISA (the
first 64b ARM ISA).</p>

<p><code>sh
➜  ~ ./android-ndk-r12b/build/tools/make_standalone_toolchain.py --arch arm64 \
  --install-dir ~/arm
</code></p>

<p>This will create a nice standalone bundle in <code>~/arm</code>.  It will contain our
cross compiler, linker, headers, libs, and
<a href="https://twitter.com/LostOracle/status/749297676223598592">sysroot (crt.o and friends)</a>.
Most Android devices are ARMv7-A, so you’d use <code>--arch arm</code>.  See the other
supported architectures for cross compiling under
<a href="https://developer.android.com/ndk/guides/standalone_toolchain.html#itc">table 4</a>.</p>

<p>You might also want to change your install-dir and possible add it to your
<code>$PATH</code>, or set <code>$CC</code> and <code>$CXX</code>.</p>

<p>Now we can compile <code>hello_world.c</code>.</p>

<p>```sh
➜  ~ cat hello_world.c</p>

<h1>include &lt;stdio.h></h1>

<p>int main () {
  puts(&ldquo;hello world&rdquo;);
}</p>

<p>➜  ~ ~/arm/bin/clang -pie hello_world.c
➜  ~ file a.out
a.out: ELF 64-bit LSB shared object, ARM aarch64, version 1 (SYSV), dynamically
linked, interpreter /system/bin/linker64,
BuildID[sha1]=ecc46648cf2c873253b3b522c0d14b91cf17c70f, not stripped
```</p>

<p><a href="http://stackoverflow.com/a/30547603">Since Android Lollipop</a>,
Android has required that executables be linked as
position independent (<code>-pie</code>) to help provide
<a href="https://en.wikipedia.org/wiki/Address_space_layout_randomization#Android">ASLR</a>.</p>

<p><code>&lt;install-dir&gt;/bin/</code> also has shell scripts with more full featured names like
<code>aarch64-linux-android-clang</code> if you prefer to have clearer named executables
in your $PATH.</p>

<p>Connect your phone, enable remote debugging, and accept the prompt for remote
debugging.</p>

<p><code>sh
➜  ~ adb push a.out /data/local/tmp/.
➜  ~ adb shell "./data/local/tmp/a.out"
hello world
</code></p>

<p>We’ll use this toolchain in a follow post to start writing some ARMv8-A
assembly.  Stay tuned.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Data Models and Word Size]]></title>
    <link href="http://nickdesaulniers.github.io/blog/2016/05/30/data-models-and-word-size/"/>
    <updated>2016-05-30T12:54:00-07:00</updated>
    <id>http://nickdesaulniers.github.io/blog/2016/05/30/data-models-and-word-size</id>
    <content type="html"><![CDATA[<p><em>This post is a follow up to
<a href="/blog/2016/05/15/whats-in-a-word/">my previous blog post about word size</a>.</em></p>

<p>Three C/C++ programmers walk into a bar.  One argues that sizeof(void*) is
equivalent to sizeof(long), one argues that sizeof(void*) is equivalent to
sizeof(int), and the third argues it’s sizeof(long long).  Simultaneously,
they’re all right, but they’re also all wrong (and need a lesson about portable
C code).  What the hell is going on?</p>

<p>One of the first few programs a programmer might write after hello world is
something like this:</p>

<p>```c</p>

<h1>include &lt;stdio.h></h1>

<p>int main () {
  printf(&ldquo;sizeof(int): %zu\n&rdquo;, sizeof(int));
  printf(&ldquo;sizeof(long): %zu\n&rdquo;, sizeof(long));
  printf(&ldquo;sizeof(long long): %zu\n&rdquo;, sizeof(long long));
  printf(&ldquo;sizeof(void<em>): %zu\n&rdquo;, sizeof(void</em>));
}
```</p>

<p><em>Note the use of the %zu format specifier, a C99 addition that isn’t portable to
older compilers!  (This post is more about considerations when porting older
code to newer machines, not about porting newer code to run on older machines.
Not having a standards compliant C compiler makes writing more portable C code
even trickier, and is a subject for another blog post).</em></p>

<p>When I run that code on my x86-64 OSX machine, I get the following output:</p>

<p><code>sh
sizeof(int): 4
sizeof(long): 8
sizeof(long long): 8
sizeof(void*): 8
</code></p>

<p>So it looks like I would be the first programmer in the story in the first
paragraph, since on my machine, it looks like sizeof(long) == sizeof(void*).
Also note how sizeof(long long) is equivalent as well.</p>

<p>But what would happen if I compiled my code on a 32 bit machine?  Luckily, my
processor has backwards compatibility with 32b binaries, so I can cross compile
it locally and still run it. Ex:</p>

<p><code>sh
➜  clang sizeof.c -Wall -Wextra -Wpedantic
➜  file a.out
a.out: Mach-O 64-bit executable x86_64
➜  clang sizeof.c -Wall -Wextra -Wpedantic -m32
➜  file a.out
a.out: Mach-O executable i386
➜  ./a.out
sizeof(int): 4
sizeof(long): 4
sizeof(long long): 8
sizeof(void*): 4
</code></p>

<p>Huh, suddenly sizeof(void*) == sizeof(int) == sizeof(long)!  This seems
to be the case of the second programmer from the story.</p>

<p>Both programmer 1 and programmer 2 might agree that the size of a pointer is
equivalent to their machine’s respective
<a href="/blog/2016/05/15/whats-in-a-word/">word size</a>,
but that too would be an incorrect assumption for portable C/C++ code!</p>

<p>Programmer 3 goes through the hellscape that is installing a working compiler
for Windows and building a 64b command line application (to be fair, installing
command line tools for OSX is worse; installing a compiler for most OS’ leaves
much to be desired).  When they run that program, they see:</p>

<p><code>
sizeof(int): 4
sizeof(long): 4
sizeof(long long): 8
sizeof(void*): 8
</code></p>

<p>This is yet a third case (the third programmer from the story).  In this case,
only sizeof(long long) is equivalent to sizeof(void*).</p>

<h3>Data Models</h3>

<p>What these programmers are seeing is known as data models.  Programmer 1 one on
a 64b x86-64 OSX machine had an LP64 data model where longs (L), (larger long
longs,) and pointers (P) are 64b, but ints were 32b.  Programmer 2 on a 32b x86
OSX machine had an ILP32 data model where ints (I), longs (L), and pointers (P)
were 32b, but long longs were 64b.  Programmer 3 on a 64b x86-64 Windows
machine had a LLP64 data model, where only long longs (LL) and pointers (P)
were 64b, ints and longs being 32b.</p>

<table>
<thead>
<tr>
<th><strong>Data model</strong> </th>
<th> <strong>sizeof(int)</strong> </th>
<th> <strong>sizeof(long)</strong> </th>
<th> <strong>sizeof(long long)</strong> </th>
<th> <strong>sizeof(void*)</strong> </th>
<th> <strong>example</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>ILP32 </td>
<td> 32b </td>
<td> 32b </td>
<td> 64b </td>
<td> 32b </td>
<td> Win32, i386 OSX &amp; Linux</td>
</tr>
<tr>
<td>LP64 </td>
<td> 32b </td>
<td> 64b </td>
<td> 64b </td>
<td> 64b </td>
<td> x86-64 OSX &amp; Linux</td>
</tr>
<tr>
<td>LLP64 </td>
<td> 32b </td>
<td> 32b </td>
<td> 64b </td>
<td> 64b </td>
<td> Win64</td>
</tr>
</tbody>
</table>


<p>There are older data models such as LP32 (Windows 3.1, Macintosh, where ints
are 16b), and more exotic ones like ILP64, and SILP64.  Knowing the data model
thus is important for portable C/C++ code.</p>

<h3>Historical Perspective</h3>

<p>Running out of address space is and will continue to be tradition in computing.
Applications become bigger as computer power and memory gets cheaper.
Companies want to sell chips that have larger word sizes to address more
memory, but early adopters don’t want to buy a computer where there favorite
application hasn’t been compiled and thus doesn’t exist on yet.  <strong>Someone from
the back shouts <em>virtual machines</em> then ducks as a chair is thrown.</strong></p>

<p><a href="http://www.unix.org/version2/whatsnew/lp64_wp.html">This document</a>
highlights some reasons why LP64 is preferred to ILP64: ILP64
made portable C code that only needed 32b of precision harder to maintain (on
ILP64 an int was 64b, but a short was 16b!).  It mentions how for data
structures that did not contain pointers, their size would be the same on LLP64
as ILP32, which is the direction Microsoft went.  LLP64 was essentially the
ILP32 model with 64b pointers.</p>

<p><em>Linux also supports an ABI called
<a href="https://en.wikipedia.org/wiki/X32_ABI">x32</a>
which can use x86-64 ISA improvements but uses 32b pointers to reduce the size
of data structures that would otherwise have 64b pointers.</em></p>

<p>For a great historical perspective on the evolution of word size and data
models, as well as the &ldquo;toil and trouble&rdquo; caused,
<a href="https://queue.acm.org/detail.cfm?id=1165766">this paper</a>
was an excellent reference.  It describes Microsoft finally abandoning support
for 16b data models in Windows XP 64.  It mentions that the industry was pretty
split between LP64, LLP64, and ILP64 as porting code from the good old days of
ILP32 would break in different ways.  That the use of long was more prevalent
in Windows applications vs the use of int in unix applications.  It also makes
the key point that a lot of programmers from the ILP32 era made assumptions
that sizeof(int) == sizeof(long) == sizeof(void*) which would not hold true
for the LP64/LLP64 era.</p>

<p>One important point the paper makes makes that’s easily missed is that typedef
wasn’t added to C until 1977 when hardware manufactures still couldn’t agree on
how many bits were in a char (CHAR_BITS) and some machines were using 24b
addressing schemes.  stdint.h and inttypes.h did not exist yet.</p>

<p><a href="/blog/2016/05/15/whats-in-a-word/">This article</a>
talks about two main categories of effects of switching from ILP32 to LP64 and
has excellent examples of problematic code.  That section near the end is worth
the read alone and makes excellent points to look for during code review.</p>

<h3>Conclusion</h3>

<p>Word size or ISA doesn’t tell you anything about sizeof(int), sizeof(long), or
sizeof(long long).  We also saw that one machine can support multiple different
data models (when I compiled and ran the same code with the -m32 flag).</p>

<p>The C standard tells you minimum guaranteed sizes for these types, but the data
model (part of the ABI, external to but abiding by the C standard) is what
tells you about the specifics sizes of standard integers and pointers.</p>

<h3>Further Reading</h3>

<ul>
<li><a href="http://www.unix.org/version2/whatsnew/lp64_wp.html">64-Bit Programming Models: Why LP64?</a></li>
<li><a href="https://queue.acm.org/detail.cfm?id=1165766">The Long Road to 64 Bits</a></li>
<li><a href="http://www.unix.org/whitepapers/64bit.html">The UNIX System &mdash; 64bit and Data Size Neutrality</a></li>
<li><a href="https://en.wikipedia.org/wiki/64-bit_computing#64-bit_data_models">64-bit data models</a></li>
<li><a href="https://docs.oracle.com/cd/E19620-01/805-3024/lp64-1/index.html">C Language Data Type Models: LP64 and ILP32</a></li>
<li><a href="https://blogs.oracle.com/nike/entry/ilp64_lp64_llp64">ILP64, LP64, LLP64</a></li>
<li><a href="https://en.wikipedia.org/wiki/X32_ABI">x32 ABI</a></li>
<li><a href="http://stackoverflow.com/a/9162072">difference between stdint.h and inttypes.h</a></li>
<li><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa384083%28v=vs.85%29.aspx">Abstract Data Models</a></li>
<li><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa384264%28v=vs.85%29.aspx">The New Data Types</a></li>
<li><a href="http://stackoverflow.com/a/13413892">Is there any reason not to use fixed width integer types (e.g. uint8_t)?</a></li>
<li><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050131-00/?p=36563/">Why did the Win64 team choose the LLP64 model?</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Additional C/C++ Tooling]]></title>
    <link href="http://nickdesaulniers.github.io/blog/2015/07/23/additional-c-slash-c-plus-plus-tooling/"/>
    <updated>2015-07-23T21:10:00-07:00</updated>
    <id>http://nickdesaulniers.github.io/blog/2015/07/23/additional-c-slash-c-plus-plus-tooling</id>
    <content type="html"><![CDATA[<p><a href="http://shop.oreilly.com/product/0636920025108.do">21st Century C by Ben Klemens</a>
was a great read. It had a section with an
intro to autotools, git, and gdb.
There are a few other useful tools that came to mind that I&rsquo;ve used when
working with C and C++ codebases. These tools are a great way to start
contributing to
<a href="https://github.com/nickdesaulniers/What-Open-Source-Means-To-Me#what-open-source-means-to-me">Open Source</a>
C &amp; C++ codebases; running these tools on
the code or adding them to the codebases.  A lot of these favor command line,
open source utilities. See how many you are familiar with!</p>

<h2>Build Tools</h2>

<h3>CMake</h3>

<p>The first tool I&rsquo;d like to take a look at is
<a href="http://www.cmake.org/overview/">CMake</a>.  CMake is yet another build tool; I
realize how contentious it is to even discuss one of the many.  From my
experience working with
<a href="https://kripken.github.io/emscripten-site/docs/introducing_emscripten/about_emscripten.html">Emscripten</a>,
we recommend the use of CMake for people
writing portable C/C++ programs.  CMake is able to emit Makefiles for unixes,
project files for Xcode on OSX, and project files for Visual Studio on Windows.
There are also a few other &ldquo;generators&rdquo; that you can use.</p>

<p>I&rsquo;ve been really impressed with CMake&rsquo;s modules for
<a href="http://www.cmake.org/cmake/help/v3.0/command/find_package.html">finding dependencies</a>
and
<a href="http://www.cmake.org/cmake/help/v3.0/module/ExternalProject.html">another for fetching and building external dependencies</a>.
I think
<a href="https://www.youtube.com/watch?v=nshzjMDD79w">C++ needs a package manager badly</a>,
and I think CMake would be a solid foundation for one.</p>

<p>The syntax isn&rsquo;t the greatest, but when I wanted to try to build one of my C++
projects on Windows which I know nothing about developing on, I was able to
install CMake and Visual Studio and get my project building.  If you can build
your code on one platform, it will usually build on the others.</p>

<p>If you&rsquo;re not worried about writing cross platform C/C++, maybe CMake is not
worth the effort, but I find it useful.  I wrestle with the syntax sometimes,
but documentation is not bad and it&rsquo;s something you deal with early on in the
development of a project and hopefully never have to touch again (how I wish
that were true).</p>

<h2>Code Formatters</h2>

<h3>ClangFormat</h3>

<p>Another contentious point of concern amongst developers is code style.
<a href="http://google-styleguide.googlecode.com/svn/trunk/cppguide.html">Big companies</a>
with lots of C++ code have
<a href="https://developer.mozilla.org/en-US/docs/Mozilla/Developer_guide/Coding_Style#CC_practices">documents</a>
explaining their stylistic choices.  Don&rsquo;t waste another hour of your life
arguing about something that really doesn&rsquo;t matter.
<a href="http://clang.llvm.org/docs/ClangFormat.html">ClangFormat</a> will help you
codify your style and format your code for you to match the style.  Simply
write the code however you want, and run the formatter on it before commiting
it.</p>

<p>It can also emit a .clang-format file that you can commit and clang-format will automatically look for that file and use the rules codified there.</p>

<h2>Linters</h2>

<h3>Flint / Flint++</h3>

<p><a href="https://github.com/facebook/flint">Flint</a> is a C++ linter in use at Facebook.
Since it moved from being
implemented in C++ to D, I&rsquo;ve had issues building it.  I&rsquo;ve had better luck
with a fork that&rsquo;s pure C++ without any of the third party dependencies Flint
originally had, called
<a href="https://github.com/L2Program/FlintPlusPlus">Flint++</a>.  While not quite full-on
static analyzers, both can be used for finding potential issues in your code
ahead of time. Linters can look at individual files in isolation; you don&rsquo;t
have to wait for long recompiles like you would with a static analyzer.</p>

<h2>Static Analyzers</h2>

<h3>Scan-build</h3>

<p><a href="http://clang-analyzer.llvm.org/scan-build.html">Scan-build</a> is a static
analyzer for C and C++ code.  You build your code &ldquo;through&rdquo; it, then use the
sibling tool scan-view to see the results.  Scan-view will emit and open an
html file that shows a list of the errors it detected.  It will insert
hyperlinks into the resulting document that step you through how certain
conditions could lead to a null pointer dereference, for example.  You can also
save and share those html files with others in the project. Static analyzers
will help you catch bugs at compile time before you run the code.</p>

<h2>Runtime Sanitizers</h2>

<h3>ASan and UBSan</h3>

<p>Clang&rsquo;s Address (ASan) and Undefined Behavior (UBSan) sanitizers are simply
compiler flags that can be used to detect errors at runtime.  ASan and UBSan
two of the more popular tools, but there are actually a ton and more being
implemented.  See the list
<a href="http://clang.llvm.org/docs/UsersManual.html#controlling-code-generation">here</a>.
These sanitizers will catch bugs at runtime, so you&rsquo;ll have to run the code
to notice any violations, at variable runtime performance costs per sanitizer.
ASan and TSan (Thread Sanitizer) made it into gcc4.8 and UBSan is in gcc4.9.</p>

<h2>Header Analysis</h2>

<h3>Include What You Use</h3>

<p><a href="https://github.com/include-what-you-use/include-what-you-use">Include What You Use</a>
(IWYU) helps you find unused or unnecessary <code>#include</code> preprocessor directives.
It should be obvious how this can help improve compile times. IWYU can also
help cut down on recompiles by recommending forward declarations under certain
conditions.
I look forward to the C++ module proposal being adopted, but until then this
tool can help you spot cruft that can be removed.</p>

<h2>Rapid Recompiles</h2>

<h3>ccache</h3>

<p><a href="https://ccache.samba.org/">ccache</a> greatly improves recompile times by caching
the results of parts of the compilation process.
<a href="https://github.com/nickdesaulniers/dotfiles/blob/49984b3e82022e5ce82e778fc8ce990f8e1e554a/.mozconfig#L1">I use when building Firefox</a>,
and it saves a great deal of time.</p>

<h3>distcc</h3>

<p><a href="https://github.com/distcc/distcc">distcc</a> is a distributed build system.
<a href="http://blog.dholbert.org/">Some folks at Mozilla</a> speed up their Firefox builds with it.</p>

<h2>Memory Leak Detectors</h2>

<h3>Valgrind</h3>

<p><a href="http://valgrind.org/info/about.html">Valgrind</a> has a
<a href="http://valgrind.org/info/about.html">suite of tools</a>, my
favorite being memcheck for finding memory leaks. Unfortunately, it doesn&rsquo;t
seem to work on OSX since 10.10.
<a href="https://code.google.com/p/address-sanitizer/wiki/ComparisonOfMemoryTools">This page</a>
referring to ASan seems to indicate that it can do everything Valgrind&rsquo;s
Memcheck can, at less of a runtime performance cost, but I&rsquo;m not sure how true
this is exactly.</p>

<h3>leaks</h3>

<p>A much more primitive tool for finding leaks from the command line, BSD&rsquo;s have
<code>leaks</code>.</p>

<p><code>bash
MallocStackLogging=1 ./a.out
leaks a.out
...
</code></p>

<h2>Profilers</h2>

<h3>Perf</h3>

<p>Perf, and
<a href="http://www.brendangregg.com/flamegraphs.html">Brendan Gregg&rsquo;s tools for emitting SVG flamegraphs</a>
from the output
are helpful for finding where time is spent in a program. In fact, there are
numerous perfomance analysis tools that are Linux specific.  My recommendation
is spend some time on <a href="http://www.brendangregg.com/linuxperf.html">Brendan Gregg&rsquo;s blog</a>.</p>

<h3>DTrace</h3>

<p>OSX doesn&rsquo;t have the same tooling as Linux, but DTrace was ported to it.  I&rsquo;ve
used it to find sampling profiles of my code before. Again,
<a href="http://www.brendangregg.com/dtrace.html">Brendan Gregg&rsquo;s blog</a> is a good
resource; there are some fantastic DTrace one liners.</p>

<h2>Debuggers</h2>

<h3>lldb</h3>

<p>lldb is analogous to gdb.  I can&rsquo;t say I have enough experience with LLDB and GDB to note the difference between the two, but LLDB did show the relative statements forward and back from the current statement by default.  I&rsquo;m informed by my friends/mortal enemies using emacs that this is less of an issue when using emacs/gdb in combination.</p>

<h2>Fuzzers</h2>

<h3>American Fuzzy Lop</h3>

<p><a href="http://lcamtuf.coredump.cx/afl/">American Fuzzy Lop</a> (AFL) is a neat program
that performs fuzzing on programs
that take inputs from files and repeatedly runs the program, modifies the
input trying to get full code coverage, and tries to find crashes.  It&rsquo;s been
getting lots of attention lately, and while I haven&rsquo;t used it myself yet, it
seems like a very powerful tool. Mozilla employs the use of fuzzers on their
JavaScript engine, for instance (not AFL, but
<a href="http://www.squarefree.com/2007/08/02/introducing-jsfunfuzz/">one developed in house</a>).</p>

<h2>Disassemblers</h2>

<h3>gobjdump</h3>

<p>If you really need to make sure the higher level code you&rsquo;re writing is getting
translated into the assembly your expecting, <code>gobjdump -S</code> will intermix the
emitted binary&rsquo;s disassembled assembly and the source code.  This was used
extensively while developing <a href="/blog/2015/05/25/interpreter-compiler-jit/">my Brainfuck JIT</a>.</p>

<h2>Conclusion</h2>

<p>Hopefully you learned of some useful tools that you should know about when
working with C or C++.  What did I miss?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interpreter, Compiler, JIT]]></title>
    <link href="http://nickdesaulniers.github.io/blog/2015/05/25/interpreter-compiler-jit/"/>
    <updated>2015-05-25T08:35:00-07:00</updated>
    <id>http://nickdesaulniers.github.io/blog/2015/05/25/interpreter-compiler-jit</id>
    <content type="html"><![CDATA[<p>Interpreters and compilers are interesting programs, themselves used to run or
translate other programs, respectively.  Those other programs that might be
interpreted might be languages like JavaScript, Ruby, Python, PHP, and Perl.  The
other programs that might be compiled are C, C++, and to some extent Java and
C#.</p>

<p>Taking the time to do translation to native machine code ahead of
time can result in better performance at runtime, but an interpreter can get to work right away without spending any time translating.  There happens to be a sweet spot
somewhere in between interpretation and compilation that combines the best of
both worlds.  Such a technique
is called Just In Time (JIT) compiling.  While interpreting, compiling, and JIT'ing code might sound radically different, they&rsquo;re actually strikingly similar.  In
this post, I hope to show how similar by comparing the code for an interpreter,
a compiler, and a JIT compiler for the language Brainfuck in around 100 lines
of C code each.</p>

<p>All of the code in the post is up on <a href="https://github.com/nickdesaulniers/bf_interpreter_jit_compiler">GitHub</a>.</p>

<p><div class="embed-video-container"><iframe src="//www.youtube.com/embed/_C5AHaS1mOA" allowfullscreen></iframe></div></p>

<p>Brainfuck is an interesting, if hard to read, language.  It only has eight
operations it can perform <code>&gt; &lt; + - . , [ ]</code>, yet is Turing complete.  There&rsquo;s nothing really to
lex; each character is a token, and if the token is not one of the eight
operators, it&rsquo;s ignored.  There&rsquo;s also not much of a grammar to parse; the
forward jumping and backwards jumping operators should be matched for well
formed input, but that&rsquo;s about it.  In this post, we&rsquo;ll skip over validating
input assuming well formed input so we can focus on the interpretation/code
generation.  You can read more about it on the
<a href="http://en.wikipedia.org/wiki/Brainfuck">Wikipedia page</a>,
which we&rsquo;ll be using as a reference throughout.</p>

<p>A Brainfuck program operates on a 30,000 element byte array initialized to all
zeros.  It starts off with an instruction pointer, that initially points to the
first element in the data array or &ldquo;tape.&rdquo;  In C code for an interpreter that
might look like:</p>

<p>```c
// Initialize the tape with 30,000 zeroes.
unsigned char tape [30000] = { 0 };</p>

<p>// Set the pointer to point at the left most cell of the tape.
unsigned char* ptr = tape;
```</p>

<p>Then, since we&rsquo;re performing an operation for each character in the Brainfuck
source, we can have a for loop over every character with a nested switch
statement containing case statements for each operator.</p>

<p>The first two operators, <code>&gt;</code> and <code>&lt;</code> increment and decrement the data pointer.</p>

<p><code>c
case '&gt;': ++ptr; break;
case '&lt;': --ptr; break;
</code></p>

<p>One thing that could be bad is that because the interpreter is written in C and
we&rsquo;re representing the tape as an array but we&rsquo;re not validating our inputs,
there&rsquo;s potential for stack buffer overrun since we&rsquo;re not performing bounds
checks.  Again, punting and assuming well formed input to keep the code and the
point more precise.</p>

<p>Next up are the <code>+</code> and <code>-</code> operators, used for incrementing and decrementing
the cell pointed to by the data pointer by one.
<code>c
case '+': ++(*ptr); break;
case '-': --(*ptr); break;
</code></p>

<p>The operators <code>.</code> and <code>,</code> provide Brainfuck&rsquo;s only means of input or output, by
writing the value pointed to by the instruction pointer to stdout as an ASCII
value, or reading one byte from stdin as an ASCII value and writing it to the
cell pointed to by the instruction pointer.</p>

<p><code>c
case '.': putchar(*ptr); break;
case ',': *ptr = getchar(); break;
</code></p>

<p>Finally, our looping constructs, <code>[</code> and <code>]</code>.  From the definition on Wikipedia
for <code>[</code>: <code>if the byte at the data pointer is zero, then instead of moving the
instruction pointer forward to the next command, jump it forward to the command
after the matching ] command</code> and for <code>]</code>: <code>if the byte at the data pointer is
nonzero, then instead of moving the instruction pointer forward to the next
command, jump it back to the command after the matching [ command.</code></p>

<p>I interpret that as:</p>

<p>```c
case &lsquo;[&rsquo;:
  if (!(*ptr)) {</p>

<pre><code>int loop = 1;
while (loop &gt; 0) {
  unsigned char current_char = input[++i];
  if (current_char == ']') {
    --loop;
  } else if (current_char == '[') {
    ++loop;
  }
}
</code></pre>

<p>  }
  break;
case &lsquo;]&rsquo;:
  if (*ptr) {</p>

<pre><code>int loop = 1;
while (loop &gt; 0) {
  unsigned char current_char = input[--i];
  if (current_char == '[') {
    --loop;
  } else if (current_char == ']') {
    ++loop;
  }
}
</code></pre>

<p>  }
  break;
```</p>

<p>Where the variable <code>loop</code> keeps track of open brackets for which we&rsquo;ve not seen
a matching close bracket, aka our nested depth.</p>

<p>So <a href="https://github.com/nickdesaulniers/bf_interpreter_jit_compiler/blob/master/interpreter.c">we can see the interpreter is quite basic</a>, in around 50 SLOC were able to
read a byte, and immediately perform an action based on the operator.  How we
perform that operation might not be the fastest though.</p>

<p>How about if we want to compile the Brainfuck source code to native machine
code?  Well, we need to know a little bit about our host machine&rsquo;s Instruction
Set Architecture (ISA) and Application Binary Interface (ABI).  The rest of the
code in this post will not be as portable as the above C code, since it assumes
an x86-64 ISA and UNIX ABI.  Now would be a good time to <a href="/blog/2014/04/18/lets-write-some-x86-64/">take a detour and learn more about writing assembly for x86-64</a>.  The interpreter is even portable enough to <a href="https://github.com/nickdesaulniers/bf_interpreter_jit_compiler#emscripten">build with Emscripten and run in a browser</a>!</p>

<p>For our compiler, we&rsquo;ll iterate over every character in the source file again,
switching on the recognized operator.  This time, instead of performing an
action right away, we&rsquo;ll print assembly instructions to stdout.  Doing so
requires running the compiler on an input file, redirecting stdout to a file,
then running the system assembler and linker on that file.  We&rsquo;ll stick with
just compiling and not assembling (though it&rsquo;s not too difficult), and linking
(for now).</p>

<p>First, we need to print a prologue for our compiled code:</p>

<p><code>c
const char* const prologue =
  ".text\n"
  ".globl _main\n"
  "_main:\n"
  "  pushq %rbp\n"
  "  movq %rsp, %rbp\n"
  "  pushq %r12\n"        // store callee saved register
  "  subq $30008, %rsp\n" // allocate 30,008 B on stack, and realign
  "  leaq (%rsp), %rdi\n" // address of beginning of tape
  "  movl $0, %esi\n"     // fill with 0's
  "  movq $30000, %rdx\n" // length 30,000 B
  "  call _memset\n"      // memset
  "  movq %rsp, %r12";
puts(prologue);
</code></p>

<p>During the linking phase, we&rsquo;ll make sure to link in libc so we can call
memset.  What we&rsquo;re doing is backing up callee saved registers we&rsquo;ll be using,
stack allocating the tape, realigning the stack (<a href="/blog/2014/04/18/lets-write-some-x86-64/">x86-64 ABI point #1</a>), copying
the address of the only item on the stack into a register for our first
argument, setting the second argument to the constant <code>0</code>, the third arg to
<code>30000</code>, then calling memset.  Finally, we use the callee saved register %r12
as our instruction pointer, which is the address into a value on the stack.</p>

<p>We
can expect the call to memset to result in a segfault if simply subtract just
30000B, and not realign for the 2 registers (64 b each, 8 B each) we pushed on
the stack.  The first pushed register aligns the stack on a 16 B boundary, the
second misaligns it; that&rsquo;s why we allocate an additional 8 B on the stack
(<a href="/blog/2014/04/18/lets-write-some-x86-64/">x86-64 ABI point #1</a>).  The stack is mis-aligned upon function entry in x86-64.
30000 is a multiple of 16.</p>

<p><img class="center" src="/images/compiler_stack_alignment.png"></p>

<p>Moving the instruction pointer (<code>&gt;</code>, <code>&lt;</code>) and modifying the pointed to value
(<code>+</code>, <code>-</code>) are straight-forward:</p>

<p><code>c
case '&gt;':
  puts("  inc %r12");
  break;
case '&lt;':
  puts("  dec %r12");
  break;
case '+':
  puts("  incb (%r12)");
  break;
case '-':
  puts("  decb (%r12)");
  break;
</code></p>

<p>For output, <code>.</code>, we need to copy the pointed to byte into the register for the
first argument to putchar.  We
explicitly zero out the register before calling putchar, since it takes an int
(32 b), but we&rsquo;re only copying a char (8 b) (Look up C&rsquo;s type promotion rules for more info).  x86-64 has an instruction that does both, movzXX, Where the first X is the source size (b, w) and the second is the destination size (w, l, q).  Thus movzbl moves a <strong>b</strong>yte (8 b) into a doub<strong>l</strong>e word (32 b).  %rdi and %edi are the same register, but %rdi is the full
64 b register, while %edi is the lowest (or least significant) 32 b.</p>

<p><code>c
case '.':
  // move byte to double word and zero upper bits since putchar takes an
  // int.
  puts("  movzbl (%r12), %edi");
  puts("  call _putchar");
  break;
</code></p>

<p>Input (<code>,</code>) is easy; call getchar, move the resulting lowest byte into the cell
pointed to by the instruction pointer.  %al is the lowest 8 b of the 64 b %rax register.</p>

<p><code>c
case ',':
  puts("  call _getchar");
  puts("  movb %al, (%r12)");
  break;    
</code></p>

<p>As usual, the looping constructs (<code>[</code> &amp; <code>]</code>) are much more work.  We have to
match up jumps to matching labels, but for an assembly program, labels must be
unique.  One way we can solve for this is whenever we encounter an opening
brace, push a monotonically increasing number that represents the numbers of
opening brackets we&rsquo;ve seen so far onto a stack like data structure.  Then, we
do our comparison and jump to what will be the label that should be produced by
the matching close label.  Next, we insert our starting label, and finally
increment the number of brackets seen.</p>

<p><code>c
case '[':
  stack_push(&amp;stack, num_brackets);
  puts("  cmpb $0, (%r12)");
  printf("  je bracket_%d_end\n", num_brackets);
  printf("bracket_%d_start:\n", num_brackets++);
  break;
</code></p>

<p>For close brackets, we pop the number of brackets seen (or rather, number of
pending open brackets which we have yet to see a matching close bracket) off of
the stack, do our comparison, jump to the matching start label, and finally
place our end label.</p>

<p><code>c
case ']':
  stack_pop(&amp;stack, &amp;matching_bracket);
  puts("  cmpb $0, (%r12)");
  printf("  jne bracket_%d_start\n", matching_bracket);
  printf("bracket_%d_end:\n", matching_bracket);
  break;
</code></p>

<p>So for sequential loops (<code>[][]</code>) we can expect the relevant assembly to look
like:</p>

<p>```gas
  cmpb $0, (%r12)
  je bracket_0_end
bracket_0_start:</p>

<p>  cmpb $0, (%r12)
  jne bracket_0_start
bracket_0_end:</p>

<p>  cmpb $0, (%r12)
  je bracket_1_end
bracket_1_start:</p>

<p>  cmpb $0, (%r12)
  jne bracket_1_start
bracket_1_end:
```</p>

<p>and for nested loops (<code>[[]]</code>), we can expect assembly like the following (note
the difference in the order of numbered start and end labels):</p>

<p>```gas
  cmpb $0, (%r12)
  je bracket_0_end
bracket_0_start:</p>

<p>  cmpb $0, (%r12)
  je bracket_1_end
bracket_1_start:</p>

<p>  cmpb $0, (%r12)
  jne bracket_1_start
bracket_1_end:</p>

<p>  cmpb $0, (%r12)
  jne bracket_0_start
bracket_0_end:
```</p>

<p>Finally, we need an epilogue to clean up the stack and callee saved registers
after ourselves.</p>

<p><code>c
const char* const epilogue =
  "  addq $30008, %rsp\n" // clean up tape from stack.
  "  popq %r12\n" // restore callee saved register
  "  popq %rbp\n"
  "  ret\n";
puts(epilogue);
</code></p>

<p>The compiler is a pain when modifying and running a Brainfuck
program; it takes a couple extra commands to compile the Brainfuck program to
assembly, assemble the assembly into an object file, link it into an
executable, and run it whereas with the interpreter we can just run it.  The
trade off is that the compiled version is quite a bit faster.  How much faster?
Let&rsquo;s save that for later.</p>

<p>Wouldn&rsquo;t it be nice if there was a translation &amp; execution technique that
didn&rsquo;t force us to compile our code every time we changed it and wanted to run
it, but also performance closer to that of compiled code?  That&rsquo;s where a JIT
compiler comes in!</p>

<p>For the basics of JITing code, make sure you read <a href="/blog/2013/04/03/basic-jit/">my previous article on the basics of JITing code in C</a>.  We&rsquo;re going to follow the same technique of
creating executable memory, copying bytes into that memory, casting it to a
function pointer, then calling it.  Just like the interpreter and the compiler,
we&rsquo;re going to do a unique action for each recognized token.  What&rsquo;s different is
that for each operator, we&rsquo;re going to push opcodes into a dynamic array, that
way it can grow based on our sequential reading of input and will simplify our calculation of relative offsets for branching operations.</p>

<p>The other special thing we&rsquo;re going to do it that we&rsquo;re going to pass
the address of our libc functions (memset, putchar, and getchar) into our
JIT'ed function at runtime.  This avoids those kooky stub functions you might
see in a disassembled executable.  That means we&rsquo;ll be invoking our JIT'ed
function like:</p>

<p><code>c
typedef void* fn_memset (void*, int, size_t);
typedef int fn_putchar (int);
typedef int fn_getchar ();
void (*jitted_func) (fn_memset, fn_putchar, fn_getchar) = mem;
jitted_func(memset, putchar, getchar);
</code></p>

<p>Where mem is our mmap'ed executable memory with our opcodes copied into it, and
the typedef&rsquo;s are for the respective function signatures for our function
pointers we&rsquo;ll be passing to our JIT'ed code.  We&rsquo;re kind of getting ahead of
ourselves, but knowing how we will invoke the dynamically created executable
code will give us an idea of how the code itself will work.</p>

<p>The prologue is quite a bit involved, so we&rsquo;ll take it step at a time.  First,
we have the usual prologue:</p>

<p><code>c
char prologue [] = {
  0x55, // push rbp
  0x48, 0x89, 0xE5, // mov rsp, rbp
</code></p>

<p>Then we want to back up our callee saved registers that we&rsquo;ll be using.  Expect horrific and difficult to debug bugs if you forget to do this.</p>

<p><code>c
  0x41, 0x54, // pushq %r12
  0x41, 0x55, // pushq %r13
  0x41, 0x56, // pushq %r14
</code></p>

<p>At this point, %rdi will contain the address of memset, %rsi will contain the
address of putchar, and %rdx will contain the address of getchar, see
<a href="/blog/2014/04/18/lets-write-some-x86-64/">x86-64 ABI point #2</a>.  We want to store these in callee saved registers before
calling any of them, else they may clobber %rdi, %rsi, or %rdx since they&rsquo;re
not &ldquo;callee saved,&rdquo; rather &ldquo;call clobbered.&rdquo;  See <a href="/blog/2014/04/18/lets-write-some-x86-64/">x86-64 ABI point #4</a>.</p>

<p><img class="center" src="/images/prologue1.png"></p>

<p><code>c
  0x49, 0x89, 0xFC, // movq %rdi, %r12
  0x49, 0x89, 0xF5, // movq %rsi, %r13
  0x49, 0x89, 0xD6, // movq %rdx, %r14
</code></p>

<p>At this point, %r12 will contain the address of memset, %r13 will contain the
address of putchar, and %r14 will contain the address of getchar.</p>

<p><img class="center" src="/images/prologue2.png"></p>

<p>Next up is allocating 30008 B on the stack:</p>

<p><code>c
  0x48, 0x81, 0xEC, 0x38, 0x75, 0x00, 0x00, // subq $30008, %rsp
</code></p>

<p>This is our first hint at how numbers, whose value is larger than the maximum
representable value in a byte, are represented on x86-64.  Where in this
instruction is the value 30008?  The answer is the 4 byte sequence
<code>0x38, 0x75, 0x00, 0x00</code>.  The x86-64 architecture is &ldquo;Little Endian,&rdquo; which
means that the least significant bit (LSB) is first and the most significant
bit (MSB) is last.  When humans do math, they typically represent numbers the
other way, or “Big Endian.”  Thus we write decimal ten as &ldquo;10&rdquo; and not &ldquo;01.&rdquo;
So that means that <code>0x38, 0x75, 0x00, 0x00</code> in Little Endian is
<code>0x00, 0x00, 0x75, 0x38</code> in Big Endian, which then is
<code>7*16^3+5*16^2+3*16^1+8*16^0</code>
which is <code>30008</code> in decimal, the amount of bytes we want to subtract from the
stack. We&rsquo;re allocating an additional 8 B on the stack for alignment
requirements, similar to the compiler.  By pushing even numbers of 64 b
registers, we need to realign our stack pointer.</p>

<p><img class="center" src="/images/prologue3.png"></p>

<p>Next in the prologue, we set up and call memset:</p>

<p><code>c
  // address of beginning of tape
  0x48, 0x8D, 0x3C, 0x24, // leaq (%rsp), %rdi
  // fill with 0's
  0xBE, 0x00, 0x00, 0x00, 0x00, // movl $0, %esi
  // length 30,000 B
  0x48, 0xC7, 0xC2, 0x30, 0x75, 0x00, 0x00, // movq $30000, %rdx
  // memset
  0x41, 0xFF, 0xD4, // callq *%r12
</code></p>

<p>After invoking memset, %rdi, %rsi, &amp; %rcx will contain garbage values since
they are &ldquo;call clobbered&rdquo; registers.  At this point we no longer need memset,
so we now use %r12 as our instruction pointer.  %rsp will point to the top
(technically the bottom) of the stack, which is the beginning of our memset'ed
tape.  That&rsquo;s the end of our prologue.</p>

<p><code>c
  0x49, 0x89, 0xE4 // movq %rsp, %r12
};
</code></p>

<p><img class="center" src="/images/prologue4.png"></p>

<p>We can then push our prologue into our dynamic array implementation:</p>

<p><code>c
vector_push(&amp;instruction_stream, prologue, sizeof(prologue))
</code></p>

<p>Now we iterate over our Brainfuck program and switch on the operations again.
For pointer increment and decrement, we just nudge %r12.</p>

<p>```c
case &lsquo;>&rsquo;:
  {</p>

<pre><code>char opcodes [] = {
  0x49, 0xFF, 0xC4 // inc %r12
};
vector_push(&amp;instruction_stream, opcodes, sizeof(opcodes));
</code></pre>

<p>  }
  break;
case &lsquo;&lt;&rsquo;:
  {</p>

<pre><code>char opcodes [] = {
  0x49, 0xFF, 0xCC // dec %r12
};
vector_push(&amp;instruction_stream, opcodes, sizeof(opcodes));
</code></pre>

<p>  }
  break;
```</p>

<p>That extra fun block in the switch statement is because in C/C++, we <a href="http://stackoverflow.com/a/8550253/1027966">can&rsquo;t
define variables in the branches of switch statements</a>.</p>

<p>Pointer deref then increment/decrement are equally uninspiring:</p>

<p>```c
case &lsquo;+&rsquo;:
  {</p>

<pre><code>char opcodes [] = {
  0x41, 0xFE, 0x04, 0x24 // incb (%r12)
};
vector_push(&amp;instruction_stream, opcodes, sizeof(opcodes));
</code></pre>

<p>  }
  break;
case &lsquo;&ndash;&rsquo;:
  {</p>

<pre><code>char opcodes [] = {
  0x41, 0xFE, 0x0C, 0x24 // decv (%r12)
};
vector_push(&amp;instruction_stream, opcodes, sizeof(opcodes));
</code></pre>

<p>  }
  break;
```</p>

<p>I/O might be interesting, but in x86-64 we have an opcode for calling the
function at the end of a pointer.  %r13 contains the address of putchar while
%r14 contains the address of getchar.</p>

<p>```c
case &lsquo;.&rsquo;:
  {</p>

<pre><code>char opcodes [] = {
  0x41, 0x0F, 0xB6, 0x3C, 0x24, // movzbl (%r12), %edi
  0x41, 0xFF, 0xD5 // callq *%r13
};
vector_push(&amp;instruction_stream, opcodes, sizeof(opcodes));
</code></pre>

<p>  }
  break;
case &lsquo;,&rsquo;:
  {</p>

<pre><code>char opcodes [] = {
  0x41, 0xFF, 0xD6, // callq *%r14
  0x41, 0x88, 0x04, 0x24 // movb %al, (%r12)
};
vector_push(&amp;instruction_stream, opcodes, sizeof(opcodes));
</code></pre>

<p>  }
  break;
```</p>

<p>Now with our looping constructs, we get to the fun part.  With the compiler, we
deferred the concept of &ldquo;relocation&rdquo; to the assembler.  We simply emitted
labels, that the assembler turned into relative offsets (jumps by values
relative to the last byte in the jump instruction).  We&rsquo;ve found ourselves in a
Catch-22 though: how many bytes forward do we jump to the matching close
bracket that we haven&rsquo;t seen yet?</p>

<p>Normally, an assembler might have a data structure known as a
&ldquo;relocation table.&rdquo;  It keeps track of the first byte after a label and jumps,
rewriting jumps-to-labels (which aren&rsquo;t kept around in the resulting binary
executable) to relative jumps.  Spidermonkey, Firefox&rsquo;s JavaScript Virtual
Machine has two classes for this, <a href="http://mxr.mozilla.org/mozilla-central/source/js/src/jit/MacroAssembler.cpp">MacroAssembler</a> and <a href="http://mxr.mozilla.org/mozilla-central/source/js/src/jit/Label.h">Label</a>.  Spidermonkey
embeds a linked list in the opcodes it generates for jumps with which it&rsquo;s yet
to see a label for.  Once it finds the label, it walks the linked list (which
itself is embedded in the emitted instruction stream) patching up these
locations as it goes.</p>

<p>For Brainfuck, we don&rsquo;t have to anything quite as fancy since each label only
ends up having one jump site.  Instead, we can use a stack of integers that are
offsets into our dynamic array, and do the relocation once we know where
exactly we&rsquo;re jumping to.</p>

<p>```c
case &lsquo;[&rsquo;:
  {</p>

<pre><code>char opcodes [] = {
  0x41, 0x80, 0x3C, 0x24, 0x00, // cmpb $0, (%r12)
  // Needs to be patched up
  0x0F, 0x84, 0x00, 0x00, 0x00, 0x00 // je &lt;32b relative offset, 2's compliment, LE&gt;
};
vector_push(&amp;instruction_stream, opcodes, sizeof(opcodes));
</code></pre>

<p>  }
  stack_push(&amp;relocation_table, instruction_stream.size); // create a label after
  break;
```</p>

<p>First we push the compare and jump opcodes, but for now we leave the relative
offset blank (four zero bytes).  We will come back and patch it up later.
Then, we push the current length of dynamic array, which just so happens to be
the offset into the instruction stream of the next instruction.</p>

<p>All of the relocation magic happens in the case for the closing bracket.</p>

<p>```c
case &lsquo;]&rsquo;:
  {</p>

<pre><code>char opcodes [] = {
  0x41, 0x80, 0x3C, 0x24, 0x00, // cmpb $0, (%r12)
  // Needs to be patched up
  0x0F, 0x85, 0x00, 0x00, 0x00, 0x00 // jne &lt;33b relative offset, 2's compliment, LE&gt;
};
vector_push(&amp;instruction_stream, opcodes, sizeof(opcodes));
</code></pre>

<p>  }
  // &hellip;
```</p>

<p>First, we push our comparison and jump instructions into the dynamic array.
We should know the relative offset we need to jump back to at this point, and
thus don&rsquo;t need to push four empty bytes, but it makes the following math a
little simpler, as were not done yet with this case.</p>

<p><code>c
  // ...
  stack_pop(&amp;relocation_table, &amp;relocation_site);
  relative_offset = instruction_stream.size - relocation_site;
  // ...
</code></p>

<p><img class="center" src="/images/relative_jump_unknown.png"></p>

<p>We pop the matching offset into the dynamic array (from the matching open
bracket), and calculate the difference from the current size of the instruction
stream to the matching offset to get our relative offset.  What&rsquo;s interesting
is that this offset is equal in magnitude for the forward and backwards jumps
that we now need to patch up.  We simply go back in our instruction stream 4 B,
and write that relative offset negated as a 32 b LE number (patching our
backwards jump), then go back to the site of our forward jump minus 4 B and
write that relative offset as a 32 b LE number (patching our forwards jump).</p>

<p><code>c
  // ...
  vector_write32LE(&amp;instruction_stream, instruction_stream.size - 4, -relative_offset);
  vector_write32LE(&amp;instruction_stream, relocation_site - 4, relative_offset);
  break;
</code></p>

<p>Thus, when writing a JIT, one must worry about manual relocation.  From the
<a href="http://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-instruction-set-reference-manual-325383.pdf">Intel 64 and IA-32 Architectures Software Developer’s Manual Volume 2 (2A, 2B &amp; 2C): Instruction Set Reference, A-Z</a> &ldquo;A relative offset
(rel8, rel16, or rel32) is generally specified as a label in assembly code, but
at the machine code level, it is encoded as a signed, 8-bit or 32-bit immediate
value, which is added to the instruction pointer.&rdquo;</p>

<p>The last thing we push onto our instruction stream is clean up code in the
epilogue.</p>

<p><code>c
char epilogue [] = {
  0x48, 0x81, 0xC4, 0x38, 0x75, 0x00, 0x00, // addq $30008, %rsp
  // restore callee saved registers
  0x41, 0x5E, // popq %r14
  0x41, 0x5D, // popq %r13
  0x41, 0x5C, // popq %r12
  0x5d, // pop rbp
  0xC3 // ret
};
vector_push(&amp;instruction_stream, epilogue, sizeof(epilogue));
</code></p>

<p>A dynamic array of bytes isn&rsquo;t really useful, so we need to create executable
memory the size of the current instruction stream and copy all of the machine
opcodes into it, cast it to a function pointer, call it, and finally clean up:</p>

<p><code>c
void* mem = mmap(NULL, instruction_stream.size, PROT_WRITE | PROT_EXEC,
  MAP_ANON | MAP_PRIVATE, -1, 0);
memcpy(mem, instruction_stream.data, instruction_stream.size);
void (*jitted_func) (fn_memset, fn_putchar, fn_getchar) = mem;
jitted_func(memcpy, putchar, getchar);
munmap(mem, instruction_stream.size);
vector_destroy(&amp;instruction_stream);
</code></p>

<p>Note: we could have used the instruction stream rewinding technique to move the address of memset, putchar, and getchar as 64 b immediate values into %r12-%r14, which would have <a href="https://github.com/nickdesaulniers/bf_interpreter_jit_compiler/pull/6/files">simplified our JIT&rsquo;d function&rsquo;s type signature</a>.</p>

<p>Compile that, and we now have <a href="https://github.com/nickdesaulniers/bf_interpreter_jit_compiler/blob/master/jit.c">a function that will JIT compile and execute Brainfuck in roughly 141 SLOC</a>.  And, we can make changes to our Brainfuck program and not have to recompile it like we did with the Brainfuck compiler.</p>

<p>Hopefully it&rsquo;s becoming apparent how similar an interpreter, compiler, and JIT
behave.  In the interpreter, we immediately execute some operation.  In the
compiler, we emit the equivalent text based assembly instructions corresponding
to what the higher level language might get translated to in the interpreter.
In the JIT, we emit the binary opcodes into executable memory and manually
perform relocation, where the binary opcodes are equivalent to the text based
assembly we might emit in the compiler.  A production ready JIT would probably have macros for each operation in the JIT would perform, so the code would look more like the compiler rather than raw arrays of bytes (though the preprocessor would translate those macros into such).  The entire process is basically disassembling C code with <code>gobjdump -S -M suffix a.out</code>, and punching in hex like one would a Gameshark.</p>

<p>Compare pointer incrementing from the three:</p>

<p>Interpreter:
<code>c
case '&gt;': ++ptr; break;
</code></p>

<p>Compiler:
<code>c
case '&gt;':
  puts("  inc %r12");
  break;
</code></p>

<p>JIT:
```c
case &lsquo;>&rsquo;:
  {</p>

<pre><code>char opcodes [] = {
  0x49, 0xFF, 0xC4 // inc %r12
};
vector_push(&amp;instruction_stream, opcodes, sizeof(opcodes));
</code></pre>

<p>  }
  break;
```</p>

<p>Or compare the full sources of the <a href="https://github.com/nickdesaulniers/bf_interpreter_jit_compiler/blob/master/interpreter.c">the interpreter</a>, <a href="https://github.com/nickdesaulniers/bf_interpreter_jit_compiler/blob/master/compiler.c">the compiler</a>, and <a href="https://github.com/nickdesaulniers/bf_interpreter_jit_compiler/blob/master/jit.c">the JIT</a>. Each at ~100 lines of code should be fairly easy to digest.</p>

<p>Let&rsquo;s now examine the performance of these three.  One of the longer running
Brainfuck programs I can find is <a href="https://github.com/nickdesaulniers/bf_interpreter_jit_compiler/blob/master/samples/mandelbrot.b">one that prints the Mandelbrot set as ASCII art to stdout</a>.</p>

<p><video width='' height='' preload='none' controls poster=''><source src='/video/jit.mp4 ' ></video></p>

<p>Running the UNIX command <code>time</code> on the interpreter, compiled
result, and the JIT, we should expect numbers similar to:</p>

<p>```
$ time ./interpreter ../samples/mandelbrot.b
43.54s user 0.03s system 99% cpu 43.581 total</p>

<p>$ ./compiler ../samples/mandelbrot.b > temp.s; ../assemble.sh temp.s; time ./a.out
3.24s user 0.01s system 99% cpu 3.254 total</p>

<p>$ time ./jit ../samples/mandelbrot.b
3.27s user 0.01s system 99% cpu 3.282 total
```</p>

<p>The interpreter is an order of magnitude slower than the compiled result or run
of the JIT.  Then again, the interpreter isn&rsquo;t able to jump back and forth as
efficiently as the compiler or JIT, since it scans back and forth for matching
brackets O(N), while the other two can jump to where they need to go in a few instructions O(1).  A production interpreter would probably translate the higher level language to a byte code, and thus be able to calculate the offsets used for jumps directly, rather than scanning back and forth.</p>

<p>The interpreter bounces back and forth between looking up an operation, then
doing something based on the operation, then lookup, etc..  The compiler and JIT preform the translation first, then the execution, not interleaving the two.</p>

<p>The compiled result is the fastest, as expected, since it doesn&rsquo;t have the
overhead the JIT does of having to read the input file or build up the
instructions to execute at runtime.  The compiler has read
and translated the input file ahead of time.</p>

<p>What if we take into account the
time it takes to compile the source code, and run it?</p>

<p><code>
$ time (./compiler ../samples/mandelbrot.b &gt; temp.s; ../assemble.sh temp.s; ./a.out)
3.27s user 0.08s system 99% cpu 3.353 total
</code></p>

<p>Including the time it takes to compile the code then run it, the compiled
results are now slightly slower than the JIT (though I bet the multiple processes we start up are suspect), but with the JIT we pay the price
to compile each and every time we run our code.  With the compiler, we pay that
tax once.  When compilation time is cheap, as is the case with our Brainfuck
compiler &amp; JIT, it makes sense to prefer the JIT; it allows us to quickly make
changes to our code and re-run it.  When compilation is expensive, we might
only want to pay the compilation tax once, especially if we plan on running the
program repeatedly.</p>

<p>JIT&rsquo;s are neat but compared to compilers can be more complex to
implement.  They also repeatedly re-parse input files and re-build instruction
streams at runtime. Where they can shine is bridging the gap for dynamically
typed languages where the runtime itself is much more dynamic, and thus harder
(if not, impossible) to optimize ahead of time.  Being able to jump into JIT&rsquo;d
native code from an
interpreter and back gives you the best of both (interpreted and compiled)
worlds.</p>
]]></content>
  </entry>
  
</feed>
