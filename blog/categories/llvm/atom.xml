<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: llvm | Nick Desaulniers]]></title>
  <link href="http://nickdesaulniers.github.io/blog/categories/llvm/atom.xml" rel="self"/>
  <link href="http://nickdesaulniers.github.io/"/>
  <updated>2019-05-12T14:31:41-07:00</updated>
  <id>http://nickdesaulniers.github.io/</id>
  <author>
    <name><![CDATA[Nick Desaulniers]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Finding compiler bugs with C-Reduce]]></title>
    <link href="http://nickdesaulniers.github.io/blog/2019/01/18/finding-compiler-bugs-with-c-reduce/"/>
    <updated>2019-01-18T00:26:00-08:00</updated>
    <id>http://nickdesaulniers.github.io/blog/2019/01/18/finding-compiler-bugs-with-c-reduce</id>
    <content type="html"><![CDATA[<p>Support for a long awaited GNU C extension,
<a href="https://gcc.gnu.org/onlinedocs/gcc/Extended-Asm.html">asm goto</a>,
is in the midst of landing in
<a href="https://reviews.llvm.org/D56571">Clang</a> and
<a href="https://reviews.llvm.org/D53765">LLVM</a>.  We want to make sure that
we release a high quality implementation, so it&rsquo;s important to test the new
patches on real code and not just small test cases.  When we hit compiler bugs
in large source files, it can be tricky to find exactly what part of
potentially large translation units are problematic.  In this post, we&rsquo;ll take
a look at using
<a href="https://embed.cs.utah.edu/creduce/">C-Reduce</a>,
a multithreaded code bisection utility for C/C++, to help narrow done a
reproducer for
<a href="https://github.com/ClangBuiltLinux/linux/issues/320">a real compiler bug</a>
(potentially; in a patch that was posted, and will be fixed before it can ship
in production) from a real code base (the Linux kernel).  It&rsquo;s mostly a post to
myself in the future, so that I can remind myself how to run C-reduce on the
Linux kernel again, since this is now the third real compiler bug it&rsquo;s helped
me track down.</p>

<p>So the bug I&rsquo;m focusing on when trying to compile the Linux kernel with Clang
is a linkage error, all the way at the end of the build.
<code>
drivers/spi/spidev.o:(__jump_table+0x74): undefined reference to `.Ltmp4'
</code>
Hmm&hellip;looks like the object file (<code>drivers/spi/spidev.o</code>), has a
section (<code>__jump_table</code>), that references a non-existent
symbol (<code>.Ltmp</code>), which looks like a temporary label that should have been
cleaned up by the compiler.  Maybe it was accidentally left behind by an
optimization pass?</p>

<p>To run C-reduce, we need a shell script that returns 0 when it should keep
reducing, and an input file.  For an input file, it&rsquo;s just way simpler to
preprocess it; this helps cut down on the compiler flags that typically
requires paths (<code>-I</code>, <code>-L</code>).</p>

<h2>Preprocess</h2>

<p>First, let&rsquo;s preprocess the source.  For the kernel, if the file compiles
correctly, the kernel&rsquo;s KBuild build process will create a file named in the
form path/to/.file.o.cmd, in our case drivers/spi/.spidev.o.cmd.  (If the file
doesn&rsquo;t compile, then
<a href="https://nickdesaulniers.github.io/blog/2017/05/31/running-clang-tidy-on-the-linux-kernel/">I&rsquo;ve had success</a>
hooking <code>make path/to/file.o</code> with
<a href="https://github.com/rizsotto/Bear">bear</a>
then getting the <code>compile_commands.json</code> for the file.)  I find it easiest to
copy this file to a new shell script, then strip out everything but the first
line.  I then replace the <code>-c -o &lt;output&gt;.o</code> with <code>-E</code>.  <code>chmod +x</code> that new
shell script, then run it (outputting to stdout) to eyeball that it looks
preprocessed, then redirect the output to a <code>.i</code> file.  Now that we have our
preprocessed input, let&rsquo;s create the C-reduce shell script.</p>

<h2>Reproducer</h2>

<p>I find it helpful to have a shell script in the form:</p>

<ol>
<li>remove previous object files</li>
<li>rebuild object files</li>
<li>disassemble object files and pipe to grep</li>
</ol>


<p>For you, it might be some different steps.
<a href="https://embed.cs.utah.edu/creduce/using/">As the docs show</a>,
you just need the shell script to return 0 when it should keep reducing.  From
our previous shell script that pre-processed the source and dumped a <code>.i</code> file,
let&rsquo;s change it back to stop before linking rather that preprocessing
(<code>s/-E/-c/</code>), and change the input to our new <code>.i</code> file.  Finally, let&rsquo;s add
the test for what we want.  Since I want C-Reduce to keep reducing until the
disassmbled object file no longer references anything <code>Ltmp</code> related, I write:</p>

<p><code>sh
$ objdump -Dr -j __jump_table spidev.o | grep Ltmp &gt; /dev/null
</code></p>

<p>Now I can run the reproducer to check that it at least returns 0, which
C-Reduce needs to get started:</p>

<p><code>sh
$ ./spidev_asm_goto.sh
$ echo $?
0
</code></p>

<h2>Running C-Reduce</h2>

<p>Now that we have a reproducer script and input file, let&rsquo;s run C-Reduce.</p>

<p>```
$ time creduce &mdash;n 40 spidev_asm_goto.sh spidev.i
===&lt; 144926 >===
running 40 interestingness tests in parallel
===&lt; pass_includes :: 0 >===
===&lt; pass_unifdef :: 0 >===
===&lt; pass_comments :: 0 >===
===&lt; pass_blank :: 0 >===
(0.7 %, 2393679 bytes)
(5.3 %, 2282207 bytes)
===&lt; pass_clang_binsrch :: replace-function-def-with-decl >===
(12.6 %, 2107372 bytes)
&hellip;
===&lt; pass_indent :: final >===
(100.0 %, 156 bytes)
===================== done ====================</p>

<p>pass statistics:
  method pass_clang_binsrch :: remove-unused-function worked 1 times and failed 0 times
&hellip;
  method pass_lines :: 0 worked 427 times and failed 998 times</p>

<pre><code>        ******** /android0/kernel-all/spidev.i ********
</code></pre>

<p>a() {
  int b;
  c();
  if (c &lt; 2)</p>

<pre><code>b = d();
</code></pre>

<p>  else {</p>

<pre><code>asm goto("1:.long b - ., %l[l_yes] - . \n\t" : : : : l_yes);
</code></pre>

<p>  l_yes:;
  }
  if (b)</p>

<pre><code>e();
</code></pre>

<p>}
creduce &mdash;n 40 spidev_asm_goto.sh spidev.i  1892.35s user 1186.10s system 817% cpu 6:16.76 total
$ wc -l spidev.i.orig
56160 spidev.i.orig
$ wc -l spidev.i
12 spidev.i
```</p>

<p>So it took C-reduce just over 6 minutes to turn >56k lines of mostly irrelevant
code into 12 when running 40 threads on my 48 core workstation.</p>

<p>It&rsquo;s also highly entertaining to watch C-Reduce work its magic. In another
terminal, I highly recommend running <code>watch -n1 cat &lt;input_file_to_creduce.i&gt;</code>
to see it pared down before your eyes.</p>

<p>Jump to 4:24 to see where things really pick up.
<a href="https://asciinema.org/a/XtD0QdiIUGhvc1G2BqTJ9gti2"><img src="https://asciinema.org/a/XtD0QdiIUGhvc1G2BqTJ9gti2.svg" alt="asciicast" /></a>
<a href="https://asciinema.org/a/zdkbvUqDsilSa5QjGJr3ANP6y"><img src="https://asciinema.org/a/zdkbvUqDsilSa5QjGJr3ANP6y.svg" alt="asciicast" /></a></p>

<p>Finally, we still want to bisect our compiler flags (the kernel uses a lot).  I
still do this process manually, and it&rsquo;s not too bad.  Having proper and
minimal steps to reproduce compiler bugs is critical.</p>

<p>That&rsquo;s enough for a great bug report for now.  In a future episode, we&rsquo;ll see
how to start pulling apart llvm to see where compilation is going amiss.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GCC vs LLVM Q3 2017: Active Developer Counts]]></title>
    <link href="http://nickdesaulniers.github.io/blog/2017/09/05/gcc-vs-llvm-q3-2017-commit-rates-and-active-developer-counts/"/>
    <updated>2017-09-05T00:20:00-07:00</updated>
    <id>http://nickdesaulniers.github.io/blog/2017/09/05/gcc-vs-llvm-q3-2017-commit-rates-and-active-developer-counts</id>
    <content type="html"><![CDATA[<p>A blog post from a few years ago that really stuck with me was Martin Olsson’s
<a href="https://mo.github.io/2015/11/04/browser-engines-active-developers-and-commit-rates.html">Browser Engines 2015: Commit Rates and Active Developer Counts</a>,
where he shows information about the number of authors and commits to popular
web browsers.  The graphs and analysis had interesting takeaways like showing
the obvious split in blink and webkit, and relative number of contributors of
the projects.  Martin had data comparing gcc to llvm from Q4 2015, but I wanted
to see what the data looked like now in Q3 2017 and wanted to share my
findings; simply rerunning the numbers.  Luckily Martin
<a href="https://github.com/mo/git-source-metrics">open sourced</a>
the scripts he used for measurements so they could be rerun.</p>

<p>Commit count and active authors in the previous 60 days is a rough estimate for
project health; the scripts don’t/can’t account for unique authors (same author
using different git commit info) and commit frequency is meaningless for
comparing developers that commit early and commit often, but let’s take a look.
Active contributors over 60 days cuts out folks who do commit to either code
bases, just not as often.  Lies, damn lies, and statistics, right? Or torture
the data enough, and it will confess anything&hellip;</p>

<p>Note that LLVM is split into a few repositories (llvm the common base, clang
the C/C++ frontend, libc++ the C++ runtime, compiler-rt the
sanitizers/built-ins/profiler lib, lld the linker, clang-tools-extra the
utility belt, lldb the debugger (there are more, these are the most active LLVM
projects)).  Later, I refer to LLVM as the grouping of these repos.</p>

<p>There’s a lot of caveats with this data.  I suspect that the separate LLVM
repo’s have a lot of overlap and have fewer active contributors when looked at
in aggregate.  That is to say you can’t simply add them else you’d be double
counting a bunch.  Also, the comparison is not quite fair since the overlap in
front-end-language and back-end-target support in these two massive projects
does not overlap in a lot of places.</p>

<p><img class="center" src="/images/gcc_clang_authors.jpg"></p>

<p>LLVM’s 60 day active contributors are ~3x-5x times GCC’s and growing, while
GCC’s 100-count hasn’t changed much since ‘04.  It’s safe to say GCC is not
dying; it’s going steady and chugging away as it has been, but it seems LLVM
has been very strong in attracting active contributors.  Either way, I’m
thankful to have not one, but two high quality open source C/C++ compilers.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Running Clang-Tidy on the Linux Kernel]]></title>
    <link href="http://nickdesaulniers.github.io/blog/2017/05/31/running-clang-tidy-on-the-linux-kernel/"/>
    <updated>2017-05-31T20:25:00-07:00</updated>
    <id>http://nickdesaulniers.github.io/blog/2017/05/31/running-clang-tidy-on-the-linux-kernel</id>
    <content type="html"><![CDATA[<p><a href="http://clang.llvm.org/extra/clang-tidy/">Clang-Tidy</a> is a linter from the LLVM
ecosystem.  I wanted to try to run it on the Linux kernel to see what kind of
bugs it would find.  The false positive rate seems pretty high (a persistent
bane to static analysis), but some patching in both the tooling and the source
can likely help bring this rate down.</p>

<p>The most straightforward way to invoke Clang-Tidy is with a compilation
database, which is a json based file that for each translation unit records</p>

<ol>
<li>The source file of the translation unit.</li>
<li>The top level directory of the source.</li>
<li>The exact arguments passed to the compiler.</li>
</ol>


<p>The exact arguments are required because <code>-D</code> and <code>-I</code> flags are necessary to
reproduce the exact Abstract Syntax Tree (AST) used to compile your code. Given
a compilation database, it&rsquo;s trivial to parse and recreate a build.  For the
kernel&rsquo;s KBuild, it&rsquo;s a lot like encoding the output of <code>make V=1</code>.</p>

<p>In order to generate a compilation database, we can use an awesome tool called
<a href="https://github.com/rizsotto/Bear">BEAR</a>. BEAR will
<a href="https://github.com/rizsotto/Bear/blob/6b07f5044f30a3070d1dc39801bcdd94395d673e/libear/ear.c#L21">hook</a>
calls to
<a href="https://linux.die.net/man/3/exec">exec</a>
and family, then write out the compilation database (compile_commands.json).</p>

<p>With BEAR installed, we can invoke the kernel&rsquo;s build with <code>bear make -j</code>. When
we&rsquo;re done:</p>

<p>```sh
➜  linux git:(nick) ✗ du -h compile_commands.json
11M compile_commands.json
➜  linux git:(nick) ✗ wc -l compile_commands.json
330296 compile_commands.json
➜  linux git:(nick) ✗ head -n 26 compile_commands.json
[</p>

<pre><code>{
    "arguments": [
        "cc",
        "-c",
        "-Wp,-MD,arch/x86/boot/tools/.build.d",
        "-Wall",
        "-Wmissing-prototypes",
        "-Wstrict-prototypes",
        "-O2",
        "-fomit-frame-pointer",
        "-std=gnu89",
        "-Wno-unused-value",
        "-Wno-unused-parameter",
        "-Wno-missing-field-initializers",
        "-I./tools/include",
        "-include",
        "include/generated/autoconf.h",
        "-D__EXPORTED_HEADERS__",
        "-o",
        "arch/x86/boot/tools/build",
        "arch/x86/boot/tools/build.c"
    ],
    "directory": "/home/nick/linux",
    "file": "arch/x86/boot/tools/build.c"
},
</code></pre>

<p>```</p>

<p>Now with Clang-Tidy (probably worthwhile to build from source, but it&rsquo;s also
available off <code>apt</code>), we want to grab
<a href="https://github.com/llvm-mirror/clang-tools-extra/blob/master/clang-tidy/tool/run-clang-tidy.py">this helper script, run-clang-tidy.py</a>
to help analyze all this code.</p>

<p><code>sh
curl -O https://raw.githubusercontent.com/llvm-mirror/clang-tools-extra/master/clang-tidy/tool/run-clang-tidy.py
</code></p>

<p>Then we can run it from the same directory as compile_commands.json:</p>

<p>```sh
python run-clang-tidy.py \
  -clang-tidy-binary /usr/bin/clang-tidy-4.0 \</p>

<blockquote><p>clang_tidy_output.txt
```</p></blockquote>

<p>This took about 1hr12min on my box. Let&rsquo;s see what the damage is:</p>

<p>```sh
➜  linux git:(nick) ✗ cat clang_tidy_output.txt \
  | grep warning: | grep -oE &lsquo;[^ ]+$&rsquo; | sort | uniq -c</p>

<pre><code> 76 [clang-analyzer-core.CallAndMessage]
 15 [clang-analyzer-core.DivideZero]
  1 [clang-analyzer-core.NonNullParamChecker]
316 [clang-analyzer-core.NullDereference]
 90 [clang-analyzer-core.UndefinedBinaryOperatorResult]
  1 [clang-analyzer-core.uninitialized.ArraySubscript]
</code></pre>

<p>   1410 [clang-analyzer-core.uninitialized.Assign]</p>

<pre><code> 10 [clang-analyzer-core.uninitialized.Branch]
  5 [clang-analyzer-core.uninitialized.UndefReturn]
 11 [clang-analyzer-cplusplus.NewDeleteLeaks]
694 [clang-analyzer-deadcode.DeadStores]
342 [clang-analyzer-security.insecureAPI.strcpy]
  2 [clang-analyzer-unix.API]
 11 [clang-analyzer-unix.Malloc]
  4 [clang-diagnostic-address-of-packed-member]
  2 [clang-diagnostic-duplicate-decl-specifier]
 98 [clang-diagnostic-implicit-int]
</code></pre>

<p>```</p>

<p>Looking through the output, there&rsquo;s seems to be almost nothing but false
positives, but who knows, maybe there&rsquo;s an actual bug or two in there.  Likely
possible patches to LLVM, its checkers, or the Linux kernel could lower the
false positive ratio.</p>

<p>If you&rsquo;re interested in seeing the kinds of warnings/outputs, I&rsquo;ve uploaded my
results run on a 4.12-rc3 based kernel that may or may not have been compiled
with Clang to
<a href="https://github.com/nickdesaulniers/linux/blob/clang_tidy/clang_tidy_output.txt.v2">my clang_tidy branch of the kernel on GitHub</a>.
As in my sorted output, I find it handy to <code>grep</code> for <code>warning:</code>. Maybe you can
find yourself a good first bug to
<a href="blog/2017/05/16/submitting-your-first-patch-to-the-linux-kernel-and-responding-to-feedback/">contribute a fix to the kernel</a>?</p>

<p>There&rsquo;s likely also
<a href="http://clang.llvm.org/extra/clang-tidy/checks/list.html">some checks that make sense to disable or enable</a>.
Clang-Tidy also allows you to
<a href="http://clang.llvm.org/extra/clang-tidy/#writing-a-clang-tidy-check">write and use your own checkers</a>.
Who knows, someone may just end up writing static
analyses tailored to the Linux kernel.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Additional C/C++ Tooling]]></title>
    <link href="http://nickdesaulniers.github.io/blog/2015/07/23/additional-c-slash-c-plus-plus-tooling/"/>
    <updated>2015-07-23T21:10:00-07:00</updated>
    <id>http://nickdesaulniers.github.io/blog/2015/07/23/additional-c-slash-c-plus-plus-tooling</id>
    <content type="html"><![CDATA[<p><a href="http://shop.oreilly.com/product/0636920025108.do">21st Century C by Ben Klemens</a>
was a great read. It had a section with an
intro to autotools, git, and gdb.
There are a few other useful tools that came to mind that I&rsquo;ve used when
working with C and C++ codebases. These tools are a great way to start
contributing to
<a href="https://github.com/nickdesaulniers/What-Open-Source-Means-To-Me#what-open-source-means-to-me">Open Source</a>
C &amp; C++ codebases; running these tools on
the code or adding them to the codebases.  A lot of these favor command line,
open source utilities. See how many you are familiar with!</p>

<h2>Build Tools</h2>

<h3>CMake</h3>

<p>The first tool I&rsquo;d like to take a look at is
<a href="http://www.cmake.org/overview/">CMake</a>.  CMake is yet another build tool; I
realize how contentious it is to even discuss one of the many.  From my
experience working with
<a href="https://kripken.github.io/emscripten-site/docs/introducing_emscripten/about_emscripten.html">Emscripten</a>,
we recommend the use of CMake for people
writing portable C/C++ programs.  CMake is able to emit Makefiles for unixes,
project files for Xcode on OSX, and project files for Visual Studio on Windows.
There are also a few other &ldquo;generators&rdquo; that you can use.</p>

<p>I&rsquo;ve been really impressed with CMake&rsquo;s modules for
<a href="http://www.cmake.org/cmake/help/v3.0/command/find_package.html">finding dependencies</a>
and
<a href="http://www.cmake.org/cmake/help/v3.0/module/ExternalProject.html">another for fetching and building external dependencies</a>.
I think
<a href="https://www.youtube.com/watch?v=nshzjMDD79w">C++ needs a package manager badly</a>,
and I think CMake would be a solid foundation for one.</p>

<p>The syntax isn&rsquo;t the greatest, but when I wanted to try to build one of my C++
projects on Windows which I know nothing about developing on, I was able to
install CMake and Visual Studio and get my project building.  If you can build
your code on one platform, it will usually build on the others.</p>

<p>If you&rsquo;re not worried about writing cross platform C/C++, maybe CMake is not
worth the effort, but I find it useful.  I wrestle with the syntax sometimes,
but documentation is not bad and it&rsquo;s something you deal with early on in the
development of a project and hopefully never have to touch again (how I wish
that were true).</p>

<h2>Code Formatters</h2>

<h3>ClangFormat</h3>

<p>Another contentious point of concern amongst developers is code style.
<a href="http://google-styleguide.googlecode.com/svn/trunk/cppguide.html">Big companies</a>
with lots of C++ code have
<a href="https://developer.mozilla.org/en-US/docs/Mozilla/Developer_guide/Coding_Style#CC_practices">documents</a>
explaining their stylistic choices.  Don&rsquo;t waste another hour of your life
arguing about something that really doesn&rsquo;t matter.
<a href="http://clang.llvm.org/docs/ClangFormat.html">ClangFormat</a> will help you
codify your style and format your code for you to match the style.  Simply
write the code however you want, and run the formatter on it before commiting
it.</p>

<p>It can also emit a .clang-format file that you can commit and clang-format will automatically look for that file and use the rules codified there.</p>

<h2>Linters</h2>

<h3>Flint / Flint++</h3>

<p><a href="https://github.com/facebook/flint">Flint</a> is a C++ linter in use at Facebook.
Since it moved from being
implemented in C++ to D, I&rsquo;ve had issues building it.  I&rsquo;ve had better luck
with a fork that&rsquo;s pure C++ without any of the third party dependencies Flint
originally had, called
<a href="https://github.com/L2Program/FlintPlusPlus">Flint++</a>.  While not quite full-on
static analyzers, both can be used for finding potential issues in your code
ahead of time. Linters can look at individual files in isolation; you don&rsquo;t
have to wait for long recompiles like you would with a static analyzer.</p>

<h2>Static Analyzers</h2>

<h3>Scan-build</h3>

<p><a href="http://clang-analyzer.llvm.org/scan-build.html">Scan-build</a> is a static
analyzer for C and C++ code.  You build your code &ldquo;through&rdquo; it, then use the
sibling tool scan-view to see the results.  Scan-view will emit and open an
html file that shows a list of the errors it detected.  It will insert
hyperlinks into the resulting document that step you through how certain
conditions could lead to a null pointer dereference, for example.  You can also
save and share those html files with others in the project. Static analyzers
will help you catch bugs at compile time before you run the code.</p>

<h2>Runtime Sanitizers</h2>

<h3>ASan and UBSan</h3>

<p>Clang&rsquo;s Address (ASan) and Undefined Behavior (UBSan) sanitizers are simply
compiler flags that can be used to detect errors at runtime.  ASan and UBSan
two of the more popular tools, but there are actually a ton and more being
implemented.  See the list
<a href="http://clang.llvm.org/docs/UsersManual.html#controlling-code-generation">here</a>.
These sanitizers will catch bugs at runtime, so you&rsquo;ll have to run the code
to notice any violations, at variable runtime performance costs per sanitizer.
ASan and TSan (Thread Sanitizer) made it into gcc4.8 and UBSan is in gcc4.9.</p>

<h2>Header Analysis</h2>

<h3>Include What You Use</h3>

<p><a href="https://github.com/include-what-you-use/include-what-you-use">Include What You Use</a>
(IWYU) helps you find unused or unnecessary <code>#include</code> preprocessor directives.
It should be obvious how this can help improve compile times. IWYU can also
help cut down on recompiles by recommending forward declarations under certain
conditions.
I look forward to the C++ module proposal being adopted, but until then this
tool can help you spot cruft that can be removed.</p>

<h2>Rapid Recompiles</h2>

<h3>ccache</h3>

<p><a href="https://ccache.samba.org/">ccache</a> greatly improves recompile times by caching
the results of parts of the compilation process.
<a href="https://github.com/nickdesaulniers/dotfiles/blob/49984b3e82022e5ce82e778fc8ce990f8e1e554a/.mozconfig#L1">I use when building Firefox</a>,
and it saves a great deal of time.</p>

<h3>distcc</h3>

<p><a href="https://github.com/distcc/distcc">distcc</a> is a distributed build system.
<a href="http://blog.dholbert.org/">Some folks at Mozilla</a> speed up their Firefox builds with it.</p>

<h2>Memory Leak Detectors</h2>

<h3>Valgrind</h3>

<p><a href="http://valgrind.org/info/about.html">Valgrind</a> has a
<a href="http://valgrind.org/info/about.html">suite of tools</a>, my
favorite being memcheck for finding memory leaks. Unfortunately, it doesn&rsquo;t
seem to work on OSX since 10.10.
<a href="https://code.google.com/p/address-sanitizer/wiki/ComparisonOfMemoryTools">This page</a>
referring to ASan seems to indicate that it can do everything Valgrind&rsquo;s
Memcheck can, at less of a runtime performance cost, but I&rsquo;m not sure how true
this is exactly.</p>

<h3>leaks</h3>

<p>A much more primitive tool for finding leaks from the command line, BSD&rsquo;s have
<code>leaks</code>.</p>

<p><code>bash
MallocStackLogging=1 ./a.out
leaks a.out
...
</code></p>

<h2>Profilers</h2>

<h3>Perf</h3>

<p>Perf, and
<a href="http://www.brendangregg.com/flamegraphs.html">Brendan Gregg&rsquo;s tools for emitting SVG flamegraphs</a>
from the output
are helpful for finding where time is spent in a program. In fact, there are
numerous perfomance analysis tools that are Linux specific.  My recommendation
is spend some time on <a href="http://www.brendangregg.com/linuxperf.html">Brendan Gregg&rsquo;s blog</a>.</p>

<h3>DTrace</h3>

<p>OSX doesn&rsquo;t have the same tooling as Linux, but DTrace was ported to it.  I&rsquo;ve
used it to find sampling profiles of my code before. Again,
<a href="http://www.brendangregg.com/dtrace.html">Brendan Gregg&rsquo;s blog</a> is a good
resource; there are some fantastic DTrace one liners.</p>

<h2>Debuggers</h2>

<h3>lldb</h3>

<p>lldb is analogous to gdb.  I can&rsquo;t say I have enough experience with LLDB and GDB to note the difference between the two, but LLDB did show the relative statements forward and back from the current statement by default.  I&rsquo;m informed by my friends/mortal enemies using emacs that this is less of an issue when using emacs/gdb in combination.</p>

<h2>Fuzzers</h2>

<h3>American Fuzzy Lop</h3>

<p><a href="http://lcamtuf.coredump.cx/afl/">American Fuzzy Lop</a> (AFL) is a neat program
that performs fuzzing on programs
that take inputs from files and repeatedly runs the program, modifies the
input trying to get full code coverage, and tries to find crashes.  It&rsquo;s been
getting lots of attention lately, and while I haven&rsquo;t used it myself yet, it
seems like a very powerful tool. Mozilla employs the use of fuzzers on their
JavaScript engine, for instance (not AFL, but
<a href="http://www.squarefree.com/2007/08/02/introducing-jsfunfuzz/">one developed in house</a>).</p>

<h2>Disassemblers</h2>

<h3>gobjdump</h3>

<p>If you really need to make sure the higher level code you&rsquo;re writing is getting
translated into the assembly your expecting, <code>gobjdump -S</code> will intermix the
emitted binary&rsquo;s disassembled assembly and the source code.  This was used
extensively while developing <a href="/blog/2015/05/25/interpreter-compiler-jit/">my Brainfuck JIT</a>.</p>

<h2>Conclusion</h2>

<p>Hopefully you learned of some useful tools that you should know about when
working with C or C++.  What did I miss?</p>
]]></content>
  </entry>
  
</feed>
